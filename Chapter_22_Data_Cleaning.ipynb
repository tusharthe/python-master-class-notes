{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 22: Data Cleaning & Preparation\n",
    "\n",
    "Handling missing data, transformations, string manipulation, and preparing data for analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Data Cleaning? (Slide 61)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>80% of data analysis</strong> is spent on loading, cleaning, and preparing data.</p>\n",
    "<p><strong>Common Issues You'll Face:</strong></p>\n",
    "<ul>\n",
    "<li><strong>Missing values</strong> ‚Äî NaN, None, empty strings, sentinel values</li>\n",
    "<li><strong>Duplicates</strong> ‚Äî repeated rows or entries</li>\n",
    "<li><strong>Inconsistent formatting</strong> ‚Äî 'NY' vs 'New York' vs 'new york'</li>\n",
    "<li><strong>Outliers</strong> ‚Äî data points far from the norm</li>\n",
    "<li><strong>Wrong data types</strong> ‚Äî numbers stored as strings</li>\n",
    "<li><strong>Messy strings</strong> ‚Äî extra whitespace, mixed case, typos</li>\n",
    "</ul>\n",
    "<p><strong>pandas provides tools for all of these!</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Clean data ‚Üí reliable analysis ‚Üí correct decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data: Filtering (Slide 62)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.547756Z",
     "iopub.status.busy": "2026-02-12T19:49:44.547594Z",
     "iopub.status.idle": "2026-02-12T19:49:44.775579Z",
     "shell.execute_reply": "2026-02-12T19:49:44.774849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "3  NaN  6.5  3.0\n",
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "3  NaN  6.5  3.0\n",
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NaN = 'Not a Number' ‚Äî pandas' missing data marker\n",
    "# .isnull()       ‚Äî True where value is NaN\n",
    "# .notnull()      ‚Äî True where value is NOT NaN\n",
    "# .dropna()       ‚Äî remove rows with ANY NaN\n",
    "# .dropna(how='all') ‚Äî only if ALL values are NaN\n",
    "# .dropna(thresh=n)  ‚Äî keep if at least n non-NaN values\n",
    "\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],\n",
    "                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
    "\n",
    "# Drop rows with any NaN\n",
    "print(data.dropna())       # Only row 0 survives\n",
    "\n",
    "# Drop only if ALL values are NaN\n",
    "print(data.dropna(how='all'))  # Row 2 dropped\n",
    "\n",
    "# Keep rows with at least 2 non-NaN values\n",
    "print(data.dropna(thresh=2))\n",
    "\n",
    "# Drop columns instead of rows\n",
    "print(data.dropna(axis=1, how='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** dropna returns a NEW object ‚Äî original is unchanged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data: Filling (Slide 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.801049Z",
     "iopub.status.busy": "2026-02-12T19:49:44.800800Z",
     "iopub.status.idle": "2026-02-12T19:49:44.811781Z",
     "shell.execute_reply": "2026-02-12T19:49:44.811150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389  0.000000 -0.342271\n",
      "3 -1.326782  0.000000 -1.001515\n",
      "4 -1.687231  0.000000  0.000000\n",
      "5  0.063503  0.000000  0.000000\n",
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389  0.500000 -0.342271\n",
      "3 -1.326782  0.500000 -1.001515\n",
      "4 -1.687231  0.500000  0.000000\n",
      "5  0.063503  0.500000  0.000000\n",
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389 -0.169779 -0.342271\n",
      "3 -1.326782 -0.169779 -1.001515\n",
      "4 -1.687231 -0.169779 -1.001515\n",
      "5  0.063503 -0.169779 -1.001515\n",
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389 -0.169779 -0.342271\n",
      "3 -1.326782 -0.169779 -1.001515\n",
      "4 -1.687231       NaN -1.001515\n",
      "5  0.063503       NaN -1.001515\n",
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389       NaN -0.342271\n",
      "3 -1.326782       NaN -1.001515\n",
      "4 -1.687231       NaN       NaN\n",
      "5  0.063503       NaN       NaN\n",
      "          0         1         2\n",
      "0 -1.259546  0.573200  0.157439\n",
      "1 -0.756249 -0.169779  1.720001\n",
      "2  0.188389  0.201711 -0.342271\n",
      "3 -1.326782  0.201711 -1.001515\n",
      "4 -1.687231  0.201711  0.133413\n",
      "5  0.063503  0.201711  0.133413\n"
     ]
    }
   ],
   "source": [
    "# .fillna(value)              ‚Äî replace NaN with a constant\n",
    "# .fillna({'col': val, ...})  ‚Äî different fill per column\n",
    "# .ffill()     ‚Äî forward fill (propagate last valid)\n",
    "# .bfill()     ‚Äî backward fill\n",
    "# .fillna(df.mean())          ‚Äî fill with column means\n",
    "# .interpolate()              ‚Äî linear interpolation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(6, 3))\n",
    "df.iloc[2:, 1] = np.nan\n",
    "df.iloc[4:, 2] = np.nan\n",
    "\n",
    "# Fill with constant\n",
    "print(df.fillna(0))\n",
    "\n",
    "# Different fill value per column\n",
    "print(df.fillna({1: 0.5, 2: 0}))\n",
    "\n",
    "# Forward fill (carry last valid value)\n",
    "print(df.ffill())\n",
    "\n",
    "# Limit how far to forward fill\n",
    "print(df.ffill(limit=2))\n",
    "\n",
    "# Limit how far to backward fill\n",
    "print(df.bfill(limit=2))\n",
    "\n",
    "# Fill with column means (very common!)\n",
    "print(df.fillna(df.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Filling with mean/median is a common imputation strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates (Slide 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.813518Z",
     "iopub.status.busy": "2026-02-12T19:49:44.813362Z",
     "iopub.status.idle": "2026-02-12T19:49:44.823270Z",
     "shell.execute_reply": "2026-02-12T19:49:44.822734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  one   3\n",
      "5  two   4\n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  one   3\n",
      "6  two   4\n",
      "    k1  k2\n",
      "0  one   1\n",
      "1  two   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  one   3\n"
     ]
    }
   ],
   "source": [
    "# .duplicated()          ‚Äî boolean: True for duplicate rows\n",
    "# .drop_duplicates()     ‚Äî remove duplicate rows\n",
    "# .duplicated(subset=['col']) ‚Äî check duplicates on specific columns\n",
    "# keep='first'           ‚Äî keep first occurrence (default)\n",
    "# keep='last'            ‚Äî keep last occurrence\n",
    "# keep=False             ‚Äî drop ALL duplicates\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],\n",
    "                     'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "\n",
    "print(data.duplicated())\n",
    "# 0    False\n",
    "# ...\n",
    "# 6     True  ‚Üê duplicate of row 5\n",
    "\n",
    "print(data.drop_duplicates())\n",
    "\n",
    "# Check duplicates on specific column only\n",
    "print(data.drop_duplicates(subset=['k1']))\n",
    "\n",
    "# Keep last occurrence instead of first\n",
    "print(data.drop_duplicates(subset=['k1', 'k2'], keep='last'))\n",
    "\n",
    "# Drop ALL occurrences of duplicated rows\n",
    "print(data.drop_duplicates(keep=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Always check df.duplicated().sum() to see how many duplicates exist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data: map & replace (Slide 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.824566Z",
     "iopub.status.busy": "2026-02-12T19:49:44.824445Z",
     "iopub.status.idle": "2026-02-12T19:49:44.833982Z",
     "shell.execute_reply": "2026-02-12T19:49:44.833328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          food  ounces animal\n",
      "0        bacon     4.0    pig\n",
      "1  pulled pork     3.0    pig\n",
      "2        bacon    12.0    pig\n",
      "3     pastrami     6.0    cow\n",
      "4  corned beef     7.5    cow\n",
      "5        bacon     8.0    pig\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ounces</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bacon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pulled chicken</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bacon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pastrami</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corned beef</td>\n",
       "      <td>7.5</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bacon</td>\n",
       "      <td>8.0</td>\n",
       "      <td>pig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             food  ounces animal\n",
       "0           bacon     4.0    pig\n",
       "1  pulled chicken     3.0    pig\n",
       "2           bacon    12.0    pig\n",
       "3        pastrami     6.0    cow\n",
       "4     corned beef     7.5    cow\n",
       "5           bacon     8.0    pig"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series.map(dict_or_func) ‚Äî transform values using a mapping\n",
    "# .replace(old, new)       ‚Äî replace specific values\n",
    "# .replace([list], [list]) ‚Äî replace multiple values at once\n",
    "# .replace({old: new})     ‚Äî replace using a dict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
    "                              'pastrami', 'corned beef', 'bacon'],\n",
    "                     'ounces': [4, 3, 12, 6, 7.5, 8]})\n",
    "\n",
    "# Map food to animal using a dict\n",
    "meat_to_animal = {'bacon': 'pig', 'pulled pork': 'pig',\n",
    "                  'pastrami': 'cow', 'corned beef': 'cow'}\n",
    "data['animal'] = data['food'].map(meat_to_animal)\n",
    "print(data)\n",
    "\n",
    "# Replace specific values\n",
    "data['food'].replace('bacon', 'turkey bacon')\n",
    "\n",
    "# Replace multiple values at once\n",
    "data.replace({'bacon': 'turkey', 'pastrami': 'tofu'})\n",
    "\n",
    "# Replace with regex\n",
    "data.replace(r'\\bpork\\b', 'chicken', regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** map is for Series; replace works on both Series and DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Axes & Indexes (Slide 66)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.835468Z",
     "iopub.status.busy": "2026-02-12T19:49:44.835334Z",
     "iopub.status.idle": "2026-02-12T19:49:44.841827Z",
     "shell.execute_reply": "2026-02-12T19:49:44.841096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OHIO', 'COLORADO', 'NEW YORK'], dtype='str')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ONE</th>\n",
       "      <th>TWO</th>\n",
       "      <th>THREE</th>\n",
       "      <th>FOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ONE  TWO  THREE  FOUR\n",
       "Ohio        0    1      2     3\n",
       "Colorado    4    5      6     7\n",
       "New York    8    9     10    11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .rename(index={old: new})    ‚Äî rename row labels\n",
    "# .rename(columns={old: new})  ‚Äî rename column labels\n",
    "# .rename(str.upper)           ‚Äî apply function to all labels\n",
    "# .index.map(func)             ‚Äî transform index labels\n",
    "# All return NEW objects (unless inplace=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                    index=['Ohio', 'Colorado', 'New York'],\n",
    "                    columns=['one', 'two', 'three', 'four'])\n",
    "\n",
    "# Transform index with a function\n",
    "data.index = data.index.map(str.upper)\n",
    "print(data.index)  # ['OHIO', 'COLORADO', 'NEW YORK']\n",
    "\n",
    "# Rename specific labels (returns new DataFrame)\n",
    "data.rename(index={'OHIO': 'INDIANA'},\n",
    "            columns={'three': 'peekaboo'})\n",
    "\n",
    "# Rename with a function\n",
    "data.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "# Rename in-place\n",
    "# data.rename(columns={'one': 'first'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** rename returns a new object ‚Äî use inplace=True to modify original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization & Binning (Slide 67)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.844038Z",
     "iopub.status.busy": "2026-02-12T19:49:44.843894Z",
     "iopub.status.idle": "2026-02-12T19:49:44.855352Z",
     "shell.execute_reply": "2026-02-12T19:49:44.854703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]\n",
      "Length: 12\n",
      "Categories (4, interval[int64, right]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]\n",
      "[0 0 0 1 0 0 2 1 3 2 2 1]\n",
      "(18, 25]     5\n",
      "(25, 35]     3\n",
      "(35, 60]     3\n",
      "(60, 100]    1\n",
      "Name: count, dtype: int64\n",
      "(-2.743, -0.715]     250\n",
      "(-0.715, 0.00103]    250\n",
      "(0.00103, 0.63]      250\n",
      "(0.63, 3.04]         250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pd.cut(data, bins)     ‚Äî bin continuous data into intervals\n",
    "# pd.cut(data, n)        ‚Äî cut into n equal-width bins\n",
    "# pd.qcut(data, n)       ‚Äî cut into n equal-SIZE bins (quantiles)\n",
    "# labels=['a', 'b', ...]  ‚Äî custom bin labels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "\n",
    "# Custom bin edges\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "cats = pd.cut(ages, bins)\n",
    "print(cats)         # [(18, 25], (18, 25], (18, 25], (25, 35], ...]\n",
    "print(cats.codes)   # [0 0 0 1 0 0 1 1 3 2 2 1]\n",
    "\n",
    "# With custom labels\n",
    "group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names)\n",
    "\n",
    "# Value counts of bins\n",
    "print(cats.value_counts())\n",
    "\n",
    "# Equal-width bins (4 bins from min to max)\n",
    "pd.cut(ages, 4, precision=2)\n",
    "\n",
    "# Quantile-based bins (equal NUMBER of points per bin)\n",
    "data = np.random.randn(1000)\n",
    "quartiles = pd.qcut(data, 4)  # 250 in each bin\n",
    "print(quartiles.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** cut = equal-width bins, qcut = equal-frequency bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting & Filtering Outliers (Slide 68)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.856950Z",
     "iopub.status.busy": "2026-02-12T19:49:44.856820Z",
     "iopub.status.idle": "2026-02-12T19:49:44.870957Z",
     "shell.execute_reply": "2026-02-12T19:49:44.870307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0            1            2            3\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000\n",
      "mean      0.030624     0.024828    -0.008255     0.030086\n",
      "std       0.963919     1.011884     1.006075     1.006964\n",
      "min      -3.019512    -2.896255    -3.241267    -2.991136\n",
      "25%      -0.612942    -0.677037    -0.675299    -0.670871\n",
      "50%       0.056187     0.020210    -0.007509     0.021158\n",
      "75%       0.664881     0.693881     0.642282     0.695878\n",
      "max       3.243093     3.852731     3.152057     3.926238\n",
      "65    -3.241267\n",
      "119    3.078881\n",
      "995    3.152057\n",
      "Name: 2, dtype: float64\n",
      "            0         1         2         3\n",
      "52   0.515048  3.852731  0.570891  1.135566\n",
      "65  -0.926930 -0.059525 -3.241267 -1.024388\n",
      "119  0.576557  0.311250  3.078881  1.119575\n",
      "403  0.883110 -0.077837 -0.180480  3.193108\n",
      "489 -2.135674  3.137749  1.056057  0.223239\n",
      "506 -3.019512  0.183850  1.800511  1.238946\n",
      "576  1.995667  3.109919  0.606723 -0.183197\n",
      "723  0.768207  0.215397  0.508269  3.926238\n",
      "929  3.243093  2.307916 -0.181449 -0.106337\n",
      "995  1.362563  1.640615  3.152057 -1.123494\n",
      "                 0            1            2            3\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000\n",
      "mean      0.030400     0.023728    -0.008245     0.028967\n",
      "std       0.963077     1.008264     1.004621     1.003207\n",
      "min      -3.000000    -2.896255    -3.000000    -2.991136\n",
      "25%      -0.612942    -0.677037    -0.675299    -0.670871\n",
      "50%       0.056187     0.020210    -0.007509     0.021158\n",
      "75%       0.664881     0.693881     0.642282     0.695878\n",
      "max       3.000000     3.000000     3.000000     3.000000\n"
     ]
    }
   ],
   "source": [
    "# Common approach: values beyond ¬±3 standard deviations\n",
    "# np.sign(data) ‚Äî returns -1, 0, or 1 (useful for capping)\n",
    "# .any(axis=1)  ‚Äî True if ANY column exceeds threshold in that row\n",
    "# .clip(lower, upper) ‚Äî cap values at boundaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame(np.random.randn(1000, 4))\n",
    "\n",
    "# Find values beyond ¬±3 standard deviations\n",
    "print(data.describe())\n",
    "col = data[2]\n",
    "print(col[col.abs() > 3])  # Outliers in column 2\n",
    "\n",
    "# Find rows with ANY column exceeding ¬±3\n",
    "print(data[(data.abs() > 3).any(axis=1)])\n",
    "\n",
    "# Cap (clip) values at ¬±3\n",
    "data = data.clip(-3, 3)  # Values clamped to [-3, 3]\n",
    "print(data.describe())   # max/min now ‚â§ 3\n",
    "\n",
    "# Alternative: use np.sign to preserve direction\n",
    "data[data.abs() > 3] = np.sign(data) * 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** clip() is the cleanest way to cap outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation & Random Sampling (Slide 69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.873285Z",
     "iopub.status.busy": "2026-02-12T19:49:44.872914Z",
     "iopub.status.idle": "2026-02-12T19:49:44.881133Z",
     "shell.execute_reply": "2026-02-12T19:49:44.880360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 0 1 2]\n",
      "    0   1   2   3\n",
      "4  16  17  18  19\n",
      "3  12  13  14  15\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "    0   1   2   3\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n",
      "1   4   5   6   7\n",
      "    0   1   2   3\n",
      "4  16  17  18  19\n",
      "3  12  13  14  15\n",
      "1   4   5   6   7\n",
      "3    6\n",
      "0    5\n",
      "3    6\n",
      "3    6\n",
      "1    7\n",
      "2   -1\n",
      "1    7\n",
      "0    5\n",
      "3    6\n",
      "1    7\n",
      "dtype: int64\n",
      "    0   1   2   3\n",
      "1   4   5   6   7\n",
      "4  16  17  18  19\n",
      "2   8   9  10  11\n"
     ]
    }
   ],
   "source": [
    "# np.random.permutation(n) ‚Äî shuffled array of [0, 1, ..., n-1]\n",
    "# df.take(indices)          ‚Äî select rows by integer position\n",
    "# df.sample(n)              ‚Äî random sample of n rows\n",
    "# df.sample(frac=0.5)       ‚Äî random 50% of rows\n",
    "# df.sample(n, replace=True) ‚Äî sample WITH replacement (bootstrap)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.arange(20).reshape((5, 4)))\n",
    "\n",
    "# Shuffle rows using permutation\n",
    "sampler = np.random.permutation(5)\n",
    "print(sampler)        # e.g. [1 0 2 3 4]\n",
    "print(df.take(sampler))\n",
    "\n",
    "# Random sample (without replacement)\n",
    "print(df.sample(n=3))\n",
    "\n",
    "# Random fraction\n",
    "print(df.sample(frac=0.6))  # 60% of rows\n",
    "\n",
    "# Bootstrap sampling (with replacement)\n",
    "choices = pd.Series([5, 7, -1, 6, 4])\n",
    "print(choices.sample(n=10, replace=True))\n",
    "\n",
    "# Reproducible sampling\n",
    "print(df.sample(n=3, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Use random_state=N for reproducible random samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables (One-Hot Encoding) (Slide 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.883268Z",
     "iopub.status.busy": "2026-02-12T19:49:44.883122Z",
     "iopub.status.idle": "2026-02-12T19:49:44.892070Z",
     "shell.execute_reply": "2026-02-12T19:49:44.891386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       a      b      c\n",
      "0  False   True  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n",
      "3  False  False   True\n",
      "4   True  False  False\n",
      "5  False   True  False\n",
      "   data1  key_a  key_b  key_c\n",
      "0      0  False   True  False\n",
      "1      1  False   True  False\n",
      "2      2   True  False  False\n",
      "3      3  False  False   True\n",
      "4      4   True  False  False\n",
      "5      5  False   True  False\n",
      "       b      c\n",
      "0   True  False\n",
      "1   True  False\n",
      "2  False  False\n",
      "3  False   True\n",
      "4  False  False\n",
      "5   True  False\n",
      "     A_a    A_b    B_x    B_y\n",
      "0   True  False   True  False\n",
      "1  False   True  False   True\n",
      "2   True  False   True  False\n"
     ]
    }
   ],
   "source": [
    "# pd.get_dummies(df['col'])   ‚Äî one-hot encode a column\n",
    "# prefix='X'                  ‚Äî custom prefix for column names\n",
    "# drop_first=True             ‚Äî drop first category (avoid multicollinearity)\n",
    "# Used to convert categorical data into numeric for ML models\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n",
    "                   'data1': range(6)})\n",
    "\n",
    "# One-hot encode 'key' column\n",
    "print(pd.get_dummies(df['key']))\n",
    "#    a  b  c\n",
    "# 0  0  1  0\n",
    "# 1  0  1  0\n",
    "# 2  1  0  0\n",
    "# 3  0  0  1\n",
    "# 4  1  0  0\n",
    "# 5  0  1  0\n",
    "\n",
    "# With prefix and join back\n",
    "dummies = pd.get_dummies(df['key'], prefix='key')\n",
    "result = df[['data1']].join(dummies)\n",
    "print(result)\n",
    "\n",
    "# Drop first column to avoid multicollinearity\n",
    "print(pd.get_dummies(df['key'], drop_first=True))\n",
    "\n",
    "# Multiple columns at once\n",
    "df2 = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['x', 'y', 'x']})\n",
    "print(pd.get_dummies(df2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** drop_first=True prevents the 'dummy variable trap' in regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods: Basics (Slide 71)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.893956Z",
     "iopub.status.busy": "2026-02-12T19:49:44.893804Z",
     "iopub.status.idle": "2026-02-12T19:49:44.899996Z",
     "shell.execute_reply": "2026-02-12T19:49:44.899361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     dave\n",
      "1    steve\n",
      "2      rob\n",
      "3      wes\n",
      "4      NaN\n",
      "dtype: str\n",
      "0      DAVE \n",
      "1      STEVE\n",
      "2        ROB\n",
      "3        WES\n",
      "4        NaN\n",
      "dtype: str\n",
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "0    7.0\n",
      "1    5.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    NaN\n",
      "dtype: float64\n",
      "0    [a, b, c]\n",
      "1    [d, e, f]\n",
      "2          NaN\n",
      "3    [g, h, i]\n",
      "dtype: object\n",
      "0      b\n",
      "1      e\n",
      "2    NaN\n",
      "3      h\n",
      "dtype: object\n",
      "0    __dave_\n",
      "1      steve\n",
      "2        rob\n",
      "3        wes\n",
      "4        NaN\n",
      "dtype: str\n"
     ]
    }
   ],
   "source": [
    "# Series.str ‚Äî access vectorized string methods\n",
    "# .str.lower()       ‚Äî lowercase\n",
    "# .str.upper()       ‚Äî uppercase\n",
    "# .str.title()       ‚Äî title case\n",
    "# .str.strip()       ‚Äî remove leading/trailing whitespace\n",
    "# .str.split(sep)    ‚Äî split into list\n",
    "# .str.replace(a, b) ‚Äî replace substring\n",
    "# .str.len()         ‚Äî length of each string\n",
    "# .str.contains(pat) ‚Äî boolean: contains pattern?\n",
    "# All methods skip NaN automatically!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.Series(['  dave ', 'steve', 'rob', 'wes', np.nan])\n",
    "\n",
    "print(data.str.strip())          # Remove whitespace\n",
    "print(data.str.upper())          # UPPERCASE\n",
    "print(data.str.contains('e'))    # [True True False True NaN]\n",
    "print(data.str.len())            # [6 5 3 3 NaN]\n",
    "\n",
    "# Split and access parts\n",
    "data2 = pd.Series(['a_b_c', 'd_e_f', np.nan, 'g_h_i'])\n",
    "print(data2.str.split('_'))      # Lists of parts\n",
    "print(data2.str.split('_').str[1])  # Second element: b, e, NaN, h\n",
    "\n",
    "# Replace\n",
    "print(data.str.replace(' ', '_'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** str methods auto-skip NaN ‚Äî no need for manual null checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods: Advanced (Slide 72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.901880Z",
     "iopub.status.busy": "2026-02-12T19:49:44.901747Z",
     "iopub.status.idle": "2026-02-12T19:49:44.907899Z",
     "shell.execute_reply": "2026-02-12T19:49:44.907200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [dave@google.com]\n",
      "1    [steve@gmail.com]\n",
      "2    [rob@outlook.com]\n",
      "dtype: object\n",
      "    name            email\n",
      "0   Dave  dave@google.com\n",
      "1  Steve  steve@gmail.com\n",
      "2    Rob  rob@outlook.com\n",
      "   a  b  c\n",
      "0  1  1  0\n",
      "1  0  1  1\n",
      "2  1  1  1\n"
     ]
    }
   ],
   "source": [
    "# .str.startswith(pat)  ‚Äî starts with pattern?\n",
    "# .str.endswith(pat)    ‚Äî ends with pattern?\n",
    "# .str.findall(regex)   ‚Äî find all regex matches\n",
    "# .str.match(regex)     ‚Äî match regex at start of string\n",
    "# .str.extract(regex)   ‚Äî extract groups into DataFrame columns\n",
    "# .str.get_dummies(sep) ‚Äî one-hot encode delimited strings\n",
    "# .str.cat(sep=',')     ‚Äî concatenate all strings\n",
    "# .str.pad(width)       ‚Äî pad strings to fixed width\n",
    "# .str.slice(start, stop) ‚Äî slice each string\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Extract structured data with regex\n",
    "data = pd.Series(['Dave dave@google.com', 'Steve steve@gmail.com',\n",
    "                  'Rob rob@outlook.com'])\n",
    "\n",
    "# Extract email addresses\n",
    "emails = data.str.findall(r'[\\w.]+@[\\w.]+')\n",
    "print(emails)\n",
    "\n",
    "# Extract into columns with named groups\n",
    "pattern = r'(?P<name>\\w+)\\s+(?P<email>[\\w.]+@[\\w.]+)'\n",
    "print(data.str.extract(pattern))\n",
    "\n",
    "# One-hot from pipe-separated values\n",
    "s = pd.Series(['a|b', 'b|c', 'a|c|b'])\n",
    "print(s.str.get_dummies(sep='|'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** str.extract with named groups is great for parsing structured text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions in pandas (Slide 73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.909516Z",
     "iopub.status.busy": "2026-02-12T19:49:44.909368Z",
     "iopub.status.idle": "2026-02-12T19:49:44.913831Z",
     "shell.execute_reply": "2026-02-12T19:49:44.913179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo', 'bar', 'baz', 'qux']\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "dtype: bool\n",
      "0    [555-123-4567]\n",
      "1                []\n",
      "2    [555-987-6543]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Python re module works with pandas str methods\n",
    "# re.findall(pattern, string)  ‚Äî all matches\n",
    "# re.search(pattern, string)   ‚Äî first match\n",
    "# re.sub(pattern, repl, string) ‚Äî substitute\n",
    "# re.split(pattern, string)    ‚Äî split on pattern\n",
    "# re.compile(pattern)          ‚Äî precompile for speed\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Common regex patterns:\n",
    "# \\d+    ‚Äî one or more digits\n",
    "# \\w+    ‚Äî one or more word characters\n",
    "# \\s+    ‚Äî one or more whitespace\n",
    "# [A-Z]  ‚Äî uppercase letter\n",
    "# .      ‚Äî any character\n",
    "# ^...$  ‚Äî start to end of string\n",
    "# (...)  ‚Äî capture group\n",
    "\n",
    "text = 'foo    bar\\t baz  \\tqux'\n",
    "print(re.split(r'\\s+', text))  # ['foo', 'bar', 'baz', 'qux']\n",
    "\n",
    "# Compile pattern for reuse (faster)\n",
    "pattern = re.compile(r'\\d{3}-\\d{3}-\\d{4}')\n",
    "phones = pd.Series(['555-123-4567', 'no phone', '555-987-6543'])\n",
    "print(phones.str.contains(pattern))\n",
    "print(phones.str.findall(pattern))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Compile patterns with re.compile() when used repeatedly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoricals (Slide 74)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:44.915177Z",
     "iopub.status.busy": "2026-02-12T19:49:44.915039Z",
     "iopub.status.idle": "2026-02-12T19:49:45.647034Z",
     "shell.execute_reply": "2026-02-12T19:49:45.646506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    1\n",
      "6    0\n",
      "7    0\n",
      "dtype: int8\n",
      "Index(['apple', 'orange'], dtype='str')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: 80,000,132 bytes\n",
      "Category: 10,000,164 bytes\n"
     ]
    }
   ],
   "source": [
    "# pd.Categorical(values)    ‚Äî create categorical type\n",
    "# .astype('category')       ‚Äî convert column to categorical\n",
    "# .cat.codes                ‚Äî integer codes for each category\n",
    "# .cat.categories           ‚Äî the unique categories\n",
    "# .cat.set_categories(new)  ‚Äî change the set of categories\n",
    "# .cat.rename_categories()  ‚Äî rename categories\n",
    "# Saves HUGE memory on repeated string values!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "values = pd.Series(['apple', 'orange', 'apple', 'apple'] * 2)\n",
    "\n",
    "# Convert to categorical (saves memory!)\n",
    "cat_values = values.astype('category')\n",
    "print(cat_values.dtype)       # category\n",
    "print(cat_values.cat.codes)   # [0 1 0 0 0 1 0 0]\n",
    "print(cat_values.cat.categories)  # ['apple', 'orange']\n",
    "\n",
    "# Memory savings on large datasets\n",
    "N = 10_000_000\n",
    "labels = pd.Series(['foo', 'bar', 'baz', 'qux'] * (N // 4))\n",
    "cat_labels = labels.astype('category')\n",
    "print(f'String: {labels.memory_usage():,} bytes')\n",
    "print(f'Category: {cat_labels.memory_usage():,} bytes')\n",
    "# Category uses ~90% less memory!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Use category dtype for columns with few unique values ‚Äî huge memory savings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical Example: Cleaning Messy Data (Slide 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:49:45.648727Z",
     "iopub.status.busy": "2026-02-12T19:49:45.648517Z",
     "iopub.status.idle": "2026-02-12T19:49:45.656009Z",
     "shell.execute_reply": "2026-02-12T19:49:45.655476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name   age         city  score\n",
      "0    Alice  25.0     New York   85.0\n",
      "1      Bob  30.0     New York   92.0\n",
      "2  Charlie  28.0     New York   85.0\n",
      "5      NaN  28.0  Los Angeles   78.0\n"
     ]
    }
   ],
   "source": [
    "# Real-world cleaning pipeline combining multiple techniques\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Messy input data\n",
    "df = pd.DataFrame({\n",
    "    'name':  ['  Alice ', 'BOB', 'charlie', 'Alice ', 'bob', None],\n",
    "    'age':   ['25', '30', 'unknown', '25', '30', '28'],\n",
    "    'city':  ['NY', 'new york', 'NYC', 'ny', 'New York', 'LA'],\n",
    "    'score': [85, 92, np.nan, 85, 92, 78]\n",
    "})\n",
    "\n",
    "# Step 1: Clean strings\n",
    "df['name'] = df['name'].str.strip().str.title()\n",
    "\n",
    "# Step 2: Standardize city names\n",
    "city_map = {'ny': 'New York', 'nyc': 'New York', 'new york': 'New York',\n",
    "            'la': 'Los Angeles'}\n",
    "df['city'] = df['city'].str.lower().map(city_map)\n",
    "\n",
    "# Step 3: Convert age to numeric (errors ‚Üí NaN)\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Step 4: Drop duplicates, fill missing\n",
    "df = df.drop_duplicates(subset=['name', 'age'])\n",
    "df['score'] = df['score'].fillna(df['score'].median())\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** pd.to_numeric(errors='coerce') converts bad values to NaN safely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Checklist (Slide 76)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>üîç Inspect:</strong></p>\n",
    "<ul>\n",
    "<li><code>df.shape</code>, <code>df.dtypes</code>, <code>df.describe()</code></li>\n",
    "<li><code>df.isnull().sum()</code> ‚Äî count missing per column</li>\n",
    "<li><code>df.duplicated().sum()</code> ‚Äî count duplicate rows</li>\n",
    "</ul>\n",
    "<p><strong>üßπ Clean:</strong></p>\n",
    "<ul>\n",
    "<li><code>dropna()</code> / <code>fillna()</code> ‚Äî handle missing data</li>\n",
    "<li><code>drop_duplicates()</code> ‚Äî remove duplicates</li>\n",
    "<li><code>str.strip().str.lower()</code> ‚Äî normalize strings</li>\n",
    "<li><code>replace()</code> / <code>map()</code> ‚Äî standardize values</li>\n",
    "<li><code>pd.to_numeric(errors='coerce')</code> ‚Äî fix wrong types</li>\n",
    "</ul>\n",
    "<p><strong>üîß Transform:</strong></p>\n",
    "<ul>\n",
    "<li><code>pd.cut()</code> / <code>pd.qcut()</code> ‚Äî bin continuous values</li>\n",
    "<li><code>get_dummies()</code> ‚Äî one-hot encode categories</li>\n",
    "<li><code>clip()</code> ‚Äî cap outliers</li>\n",
    "<li><code>.astype('category')</code> ‚Äî save memory on repeated strings</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Run this checklist on every new dataset before analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
