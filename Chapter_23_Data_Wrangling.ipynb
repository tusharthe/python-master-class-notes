{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 23: Data Wrangling — Join, Combine, Reshape\n",
    "\n",
    "Merging datasets, concatenation, reshaping, and pivoting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Data Wrangling? (Slide 78)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Real-world data lives in <strong>multiple tables</strong>. You need to combine, reshape, and reorganize it before analysis.</p>\n",
    "<p><strong>Core Operations:</strong></p>\n",
    "<ul>\n",
    "<li><strong>Merge / Join</strong> — combine datasets by matching keys (like SQL JOIN)</li>\n",
    "<li><strong>Concatenate</strong> — stack datasets vertically or horizontally</li>\n",
    "<li><strong>Reshape</strong> — pivot between long and wide formats</li>\n",
    "</ul>\n",
    "<p><strong>pandas Tools:</strong></p>\n",
    "<ul>\n",
    "<li><code>pd.merge()</code> — database-style joins on columns or indexes</li>\n",
    "<li><code>pd.concat()</code> — glue DataFrames together along an axis</li>\n",
    "<li><code>.stack()</code> / <code>.unstack()</code> — pivot between row and column levels</li>\n",
    "<li><code>.pivot_table()</code> — spreadsheet-style pivot with aggregation</li>\n",
    "<li><code>pd.melt()</code> — unpivot wide format to long format</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Merging is the pandas equivalent of SQL JOIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.merge: Inner Join (Slide 79)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.438254Z",
     "iopub.status.busy": "2026-02-12T19:53:12.438083Z",
     "iopub.status.idle": "2026-02-12T19:53:12.640375Z",
     "shell.execute_reply": "2026-02-12T19:53:12.639430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data1  data2\n",
      "0   b      0      1\n",
      "1   b      1      1\n",
      "2   a      2      0\n",
      "3   a      4      0\n",
      "4   a      5      0\n",
      "5   b      6      1\n",
      "  lkey  data1 rkey  data2\n",
      "0    b      0    b      1\n",
      "1    b      1    b      1\n",
      "2    a      2    a      0\n"
     ]
    }
   ],
   "source": [
    "# pd.merge(left, right, on='key') — merge two DataFrames on a column\n",
    "# how='inner'  — keep only matching rows (default)\n",
    "# how='left'   — keep all left rows, NaN for no match\n",
    "# how='right'  — keep all right rows\n",
    "# how='outer'  — keep all rows from both\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
    "                    'data1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'],\n",
    "                    'data2': range(3)})\n",
    "\n",
    "# Inner join (default) — only matching keys\n",
    "print(pd.merge(df1, df2, on='key'))\n",
    "# 'c' from df1 dropped (not in df2)\n",
    "# 'd' from df2 dropped (not in df1)\n",
    "\n",
    "# Different column names? Use left_on / right_on\n",
    "df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c'],\n",
    "                    'data1': range(4)})\n",
    "df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n",
    "                    'data2': range(3)})\n",
    "print(pd.merge(df3, df4, left_on='lkey', right_on='rkey'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Inner join = intersection of keys (only matching rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.merge: Outer, Left, Right Joins (Slide 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.662853Z",
     "iopub.status.busy": "2026-02-12T19:53:12.662663Z",
     "iopub.status.idle": "2026-02-12T19:53:12.677390Z",
     "shell.execute_reply": "2026-02-12T19:53:12.676700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  val1  val2\n",
      "0   a   1.0   NaN\n",
      "1   b   2.0   4.0\n",
      "2   c   3.0   5.0\n",
      "3   d   NaN   6.0\n",
      "  key  val1  val2\n",
      "0   a     1   NaN\n",
      "1   b     2   4.0\n",
      "2   c     3   5.0\n",
      "  key  val1  val2\n",
      "0   b   2.0     4\n",
      "1   c   3.0     5\n",
      "2   d   NaN     6\n",
      "  key1 key2  lval  rval\n",
      "0    a  one   1.0   4.0\n",
      "1    a  two   2.0   NaN\n",
      "2    b  one   3.0   5.0\n",
      "3    b  two   NaN   6.0\n",
      "  key  val1  val2\n",
      "0   b     2     4\n",
      "1   c     3     5\n"
     ]
    }
   ],
   "source": [
    "# how='outer' — ALL keys from BOTH tables (NaN where no match)\n",
    "# how='left'  — ALL keys from LEFT table\n",
    "# how='right' — ALL keys from RIGHT table\n",
    "# suffixes=('_left', '_right') — rename overlapping columns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'key': ['a', 'b', 'c'], 'val1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['b', 'c', 'd'], 'val2': [4, 5, 6]})\n",
    "\n",
    "# Outer join — union of all keys\n",
    "print(pd.merge(df1, df2, on='key', how='outer'))\n",
    "#   key  val1  val2\n",
    "#    a   1.0   NaN\n",
    "#    b   2.0   4.0\n",
    "#    c   3.0   5.0\n",
    "#    d   NaN   6.0\n",
    "\n",
    "# Left join — all rows from df1\n",
    "print(pd.merge(df1, df2, on='key', how='left'))\n",
    "\n",
    "# Right join — all rows from df2\n",
    "print(pd.merge(df1, df2, on='key', how='right'))\n",
    "\n",
    "# Multiple keys\n",
    "left = pd.DataFrame({'key1': ['a', 'a', 'b'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3]})\n",
    "right = pd.DataFrame({'key1': ['a', 'b', 'b'], 'key2': ['one', 'one', 'two'], 'rval': [4, 5, 6]})\n",
    "print(pd.merge(left, right, on=['key1', 'key2'], how='outer'))\n",
    "\n",
    "# Handle duplicate column names\n",
    "print(pd.merge(df1, df2, on='key', suffixes=('_L', '_R')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Left join is most common — keep all your rows, add matching data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on Index (Slide 81)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.679166Z",
     "iopub.status.busy": "2026-02-12T19:53:12.679032Z",
     "iopub.status.idle": "2026-02-12T19:53:12.688079Z",
     "shell.execute_reply": "2026-02-12T19:53:12.687482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value  group_val\n",
      "0   a      0        3.5\n",
      "1   b      1        7.0\n",
      "2   a      2        3.5\n",
      "3   a      3        3.5\n",
      "4   b      4        7.0\n",
      "   val  val2\n",
      "a  1.0   NaN\n",
      "b  2.0   4.0\n",
      "c  3.0   5.0\n",
      "d  NaN   6.0\n",
      "   val  val2\n",
      "a  1.0   NaN\n",
      "b  2.0   4.0\n",
      "c  3.0   5.0\n",
      "d  NaN   6.0\n",
      "   val    x    y\n",
      "a    1  1.0  3.0\n",
      "b    2  2.0  NaN\n",
      "c    3  NaN  4.0\n"
     ]
    }
   ],
   "source": [
    "# left_index=True  — use left DataFrame's index as join key\n",
    "# right_index=True — use right DataFrame's index as join key\n",
    "# df.join(other)   — shorthand for merging on index\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
    "                     'value': range(6)})\n",
    "right = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "\n",
    "# Merge left column with right index\n",
    "print(pd.merge(left, right, left_on='key', right_index=True))\n",
    "\n",
    "# Both indexes\n",
    "left2 = pd.DataFrame({'val': [1, 2, 3]}, index=['a', 'b', 'c'])\n",
    "right2 = pd.DataFrame({'val2': [4, 5, 6]}, index=['b', 'c', 'd'])\n",
    "print(pd.merge(left2, right2, left_index=True, right_index=True,\n",
    "               how='outer'))\n",
    "\n",
    "# .join() shorthand (merges on index by default)\n",
    "print(left2.join(right2, how='outer'))\n",
    "\n",
    "# Join multiple DataFrames at once\n",
    "other1 = pd.DataFrame({'x': [1, 2]}, index=['a', 'b'])\n",
    "other2 = pd.DataFrame({'y': [3, 4]}, index=['a', 'c'])\n",
    "print(left2.join([other1, other2], how='outer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** .join() is a convenient shorthand for index-based merges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.concat: Stacking DataFrames (Slide 82)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.689699Z",
     "iopub.status.busy": "2026-02-12T19:53:12.689572Z",
     "iopub.status.idle": "2026-02-12T19:53:12.696869Z",
     "shell.execute_reply": "2026-02-12T19:53:12.696350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "d    3\n",
      "e    4\n",
      "f    5\n",
      "g    6\n",
      "dtype: int64\n",
      "     0    1    2\n",
      "a  0.0  NaN  NaN\n",
      "b  1.0  NaN  NaN\n",
      "c  NaN  2.0  NaN\n",
      "d  NaN  3.0  NaN\n",
      "e  NaN  4.0  NaN\n",
      "f  NaN  NaN  5.0\n",
      "g  NaN  NaN  6.0\n",
      "one    a    0\n",
      "       b    1\n",
      "two    c    2\n",
      "       d    3\n",
      "       e    4\n",
      "three  f    5\n",
      "       g    6\n",
      "dtype: int64\n",
      "   A  B\n",
      "0  1  3\n",
      "1  2  4\n",
      "2  5  7\n",
      "3  6  8\n"
     ]
    }
   ],
   "source": [
    "# pd.concat([df1, df2, ...])          — stack vertically (default)\n",
    "# pd.concat([df1, df2], axis=1)       — stack horizontally\n",
    "# ignore_index=True                   — reset index 0, 1, 2, ...\n",
    "# keys=['a', 'b']                     — add hierarchical index\n",
    "# join='inner'                        — only keep shared columns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
    "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = pd.Series([5, 6], index=['f', 'g'])\n",
    "\n",
    "# Vertical concat (default)\n",
    "print(pd.concat([s1, s2, s3]))  # a=0, b=1, c=2, ..., g=6\n",
    "\n",
    "# Horizontal concat\n",
    "print(pd.concat([s1, s2, s3], axis=1))  # NaN where missing\n",
    "\n",
    "# Add keys to identify source\n",
    "result = pd.concat([s1, s2, s3], keys=['one', 'two', 'three'])\n",
    "print(result)  # Hierarchical index\n",
    "\n",
    "# DataFrames — reset index after concat\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "print(pd.concat([df1, df2], ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Use ignore_index=True when original indexes are meaningless\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine_first: Patching Missing Data (Slide 83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.698700Z",
     "iopub.status.busy": "2026-02-12T19:53:12.698525Z",
     "iopub.status.idle": "2026-02-12T19:53:12.707693Z",
     "shell.execute_reply": "2026-02-12T19:53:12.707100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.0\n",
      "b    4.5\n",
      "c    3.5\n",
      "d    NaN\n",
      "e    2.5\n",
      "f    5.0\n",
      "dtype: float64\n",
      "     a    b\n",
      "0  1.0  NaN\n",
      "1  4.0  2.0\n",
      "2  5.0  4.0\n",
      "3  3.0  6.0\n"
     ]
    }
   ],
   "source": [
    "# .combine_first(other) — fill NaN values in self with values from other\n",
    "# Think of it as: 'patch holes in my data with this backup'\n",
    "# np.where(pd.isnull(a), b, a) — equivalent logic\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],\n",
    "              index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "b = pd.Series([0., np.nan, 2., np.nan, np.nan, 5.],\n",
    "              index=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "\n",
    "# Fill NaN in 'a' with values from 'b'\n",
    "print(a.combine_first(b))\n",
    "# a    5.0   ← was NaN, filled from b\n",
    "# b    4.5   ← kept from a\n",
    "# c    3.5   ← kept from a\n",
    "# d    2.0   ← was NaN, filled from b\n",
    "# e    2.5   ← kept from a\n",
    "# f    0.0   ← was NaN, filled from b\n",
    "\n",
    "# Works on DataFrames too\n",
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan],\n",
    "                    'b': [np.nan, 2., np.nan, 6.]})\n",
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3.],\n",
    "                    'b': [np.nan, 3., 4., 5.]})\n",
    "print(df1.combine_first(df2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** combine_first = 'use my data, patch holes from the other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping: stack & unstack (Slide 84)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.709849Z",
     "iopub.status.busy": "2026-02-12T19:53:12.709688Z",
     "iopub.status.idle": "2026-02-12T19:53:12.720859Z",
     "shell.execute_reply": "2026-02-12T19:53:12.720133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio      one      0\n",
      "          two      1\n",
      "          three    2\n",
      "Colorado  one      3\n",
      "          two      4\n",
      "          three    5\n",
      "dtype: int64\n",
      "          one  two  three\n",
      "Ohio        0    1      2\n",
      "Colorado    3    4      5\n",
      "       Ohio  Colorado\n",
      "one       0         3\n",
      "two       1         4\n",
      "three     2         5\n",
      "   four  one  three  two\n",
      "a   NaN  1.0    NaN  2.0\n",
      "b   4.0  NaN    3.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# .stack()    — pivot COLUMNS → ROWS (wide → long)\n",
    "# .unstack()  — pivot ROWS → COLUMNS (long → wide)\n",
    "# .unstack(level) — specify which level to unstack\n",
    "# Both return a view when possible\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
    "                    index=['Ohio', 'Colorado'],\n",
    "                    columns=['one', 'two', 'three'])\n",
    "\n",
    "# stack: columns become inner row index\n",
    "stacked = data.stack()\n",
    "print(stacked)\n",
    "# Ohio      one      0\n",
    "#           two      1\n",
    "#           three    2\n",
    "# Colorado  one      3\n",
    "#           two      4\n",
    "#           three    5\n",
    "\n",
    "# unstack: inner row index → columns\n",
    "print(stacked.unstack())     # Back to original\n",
    "print(stacked.unstack(0))    # Unstack the OTHER level\n",
    "\n",
    "# Unstacking with missing data → NaN fills the gaps\n",
    "s = pd.Series([1, 2, 3, 4], index=[['a', 'a', 'b', 'b'],\n",
    "                                    ['one', 'two', 'three', 'four']])\n",
    "print(s.unstack())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** stack = wide→long, unstack = long→wide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting: Long to Wide (Slide 85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.722605Z",
     "iopub.status.busy": "2026-02-12T19:53:12.722466Z",
     "iopub.status.idle": "2026-02-12T19:53:12.730801Z",
     "shell.execute_reply": "2026-02-12T19:53:12.730055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date item  value\n",
      "0  2024-01-01    A      1\n",
      "1  2024-01-01    B      2\n",
      "2  2024-01-01    C      3\n",
      "3  2024-01-02    A      4\n",
      "4  2024-01-02    B      5\n",
      "5  2024-01-02    C      6\n",
      "item        A  B  C\n",
      "date               \n",
      "2024-01-01  1  2  3\n",
      "2024-01-02  4  5  6\n",
      "         date item  value\n",
      "0  2024-01-01    A      1\n",
      "1  2024-01-02    A      4\n",
      "2  2024-01-01    B      2\n",
      "3  2024-01-02    B      5\n",
      "4  2024-01-01    C      3\n",
      "5  2024-01-02    C      6\n"
     ]
    }
   ],
   "source": [
    "# df.pivot(index, columns, values) — reshape long → wide\n",
    "# ⚠️ Fails if duplicate (index, column) pairs exist!\n",
    "# Use pivot_table() for duplicates (it aggregates)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'date': ['2024-01-01'] * 3 + ['2024-01-02'] * 3,\n",
    "                     'item': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                     'value': [1, 2, 3, 4, 5, 6]})\n",
    "\n",
    "# Long format (tidy)\n",
    "print(data)\n",
    "#         date item  value\n",
    "# 0 2024-01-01    A      1\n",
    "# 1 2024-01-01    B      2\n",
    "# ...\n",
    "\n",
    "# Pivot to wide format\n",
    "wide = data.pivot(index='date', columns='item', values='value')\n",
    "print(wide)\n",
    "# item         A  B  C\n",
    "# date\n",
    "# 2024-01-01   1  2  3\n",
    "# 2024-01-02   4  5  6\n",
    "\n",
    "# Reverse: wide → long with pd.melt()\n",
    "long = pd.melt(wide.reset_index(), id_vars=['date'],\n",
    "               value_vars=['A', 'B', 'C'])\n",
    "print(long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** pivot for unique keys; pivot_table when you need aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot_table: Aggregated Pivoting (Slide 86)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.732416Z",
     "iopub.status.busy": "2026-02-12T19:53:12.732253Z",
     "iopub.status.idle": "2026-02-12T19:53:12.753645Z",
     "shell.execute_reply": "2026-02-12T19:53:12.753033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B         one       two\n",
      "A                      \n",
      "bar  1.760446  1.240286\n",
      "foo  1.089991 -0.076091\n",
      "            C         D\n",
      "A                      \n",
      "bar  4.761178  0.812009\n",
      "foo  2.103892  1.257166\n",
      "All  6.865070  2.069175\n",
      "         mean           count    \n",
      "B         one       two   one two\n",
      "A                                \n",
      "bar  1.760446  1.240286     2   1\n",
      "foo  1.089991 -0.076091     2   1\n"
     ]
    }
   ],
   "source": [
    "# df.pivot_table(values, index, columns, aggfunc)\n",
    "# aggfunc='mean'    — average (default)\n",
    "# aggfunc='sum'     — total\n",
    "# aggfunc='count'   — count\n",
    "# aggfunc=['mean', 'sum'] — multiple aggregations\n",
    "# margins=True      — add row/column totals\n",
    "# fill_value=0      — replace NaN with 0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'],\n",
    "                   'B': ['one', 'one', 'two', 'two', 'one', 'one'],\n",
    "                   'C': np.random.randn(6),\n",
    "                   'D': np.random.randn(6)})\n",
    "\n",
    "# Average of C grouped by A and B\n",
    "print(df.pivot_table(values='C', index='A', columns='B',\n",
    "                     aggfunc='mean'))\n",
    "\n",
    "# Sum with row/column totals\n",
    "print(df.pivot_table(values=['C', 'D'], index='A',\n",
    "                     aggfunc='sum', margins=True))\n",
    "\n",
    "# Multiple aggregation functions\n",
    "print(df.pivot_table(values='C', index='A', columns='B',\n",
    "                     aggfunc=['mean', 'count'],\n",
    "                     fill_value=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** pivot_table is like Excel's PivotTable feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.melt: Wide to Long (Slide 87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.755343Z",
     "iopub.status.busy": "2026-02-12T19:53:12.755198Z",
     "iopub.status.idle": "2026-02-12T19:53:12.761581Z",
     "shell.execute_reply": "2026-02-12T19:53:12.760912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  math  science  english\n",
      "0    Alice    90       85       88\n",
      "1      Bob    80       95       78\n",
      "2  Charlie    70       75       92\n",
      "      name  subject  score\n",
      "0    Alice     math     90\n",
      "1      Bob     math     80\n",
      "2  Charlie     math     70\n",
      "3    Alice  science     85\n",
      "4      Bob  science     95\n",
      "5  Charlie  science     75\n",
      "6    Alice  english     88\n",
      "7      Bob  english     78\n",
      "8  Charlie  english     92\n"
     ]
    }
   ],
   "source": [
    "# pd.melt(df, id_vars, value_vars) — unpivot wide → long\n",
    "# id_vars=['col']    — columns to KEEP as identifiers\n",
    "# value_vars=['a','b'] — columns to UNPIVOT into rows\n",
    "# var_name='name'    — name for the 'variable' column\n",
    "# value_name='val'   — name for the 'value' column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Wide format (one column per measurement)\n",
    "df = pd.DataFrame({'name': ['Alice', 'Bob', 'Charlie'],\n",
    "                   'math': [90, 80, 70],\n",
    "                   'science': [85, 95, 75],\n",
    "                   'english': [88, 78, 92]})\n",
    "print(df)\n",
    "\n",
    "# Melt to long format (one row per measurement)\n",
    "long = pd.melt(df, id_vars=['name'],\n",
    "               value_vars=['math', 'science', 'english'],\n",
    "               var_name='subject', value_name='score')\n",
    "print(long)\n",
    "#      name  subject  score\n",
    "# 0   Alice     math     90\n",
    "# 1     Bob     math     80\n",
    "# 2 Charlie     math     70\n",
    "# 3   Alice  science     85\n",
    "# ...\n",
    "\n",
    "# Melt is the inverse of pivot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** melt = unpivot. Converts wide tables into tidy long format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.crosstab: Frequency Tables (Slide 88)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.763091Z",
     "iopub.status.busy": "2026-02-12T19:53:12.762914Z",
     "iopub.status.idle": "2026-02-12T19:53:12.789259Z",
     "shell.execute_reply": "2026-02-12T19:53:12.788729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handedness   L   R\n",
      "gender            \n",
      "F           25  31\n",
      "M           19  25\n",
      "handedness   L   R  All\n",
      "gender                 \n",
      "F           25  31   56\n",
      "M           19  25   44\n",
      "All         44  56  100\n",
      "handedness     L     R\n",
      "gender                \n",
      "F           0.25  0.31\n",
      "M           0.19  0.25\n",
      "handedness    L   R\n",
      "gender city        \n",
      "F      CHI    8   9\n",
      "       LA    11  12\n",
      "       NY     6  10\n",
      "M      CHI    9   7\n",
      "       LA     2   6\n",
      "       NY     8  12\n"
     ]
    }
   ],
   "source": [
    "# pd.crosstab(row_data, col_data) — frequency table\n",
    "# Similar to pivot_table with aggfunc='count'\n",
    "# normalize=True     — show proportions instead of counts\n",
    "# normalize='index'  — normalize across rows\n",
    "# normalize='columns' — normalize down columns\n",
    "# margins=True       — add row/column totals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({'gender': np.random.choice(['M', 'F'], 100),\n",
    "                   'handedness': np.random.choice(['R', 'L'], 100),\n",
    "                   'city': np.random.choice(['NY', 'LA', 'CHI'], 100)})\n",
    "\n",
    "# Basic frequency table\n",
    "print(pd.crosstab(df.gender, df.handedness))\n",
    "# handedness   L   R\n",
    "# gender\n",
    "# F           25  30\n",
    "# M           20  25\n",
    "\n",
    "# With margins (totals)\n",
    "print(pd.crosstab(df.gender, df.handedness, margins=True))\n",
    "\n",
    "# Proportions\n",
    "print(pd.crosstab(df.gender, df.handedness, normalize=True))\n",
    "\n",
    "# Multiple variables\n",
    "print(pd.crosstab([df.gender, df.city], df.handedness))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** crosstab is great for quick categorical data exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy Basics (Slide 89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.791229Z",
     "iopub.status.busy": "2026-02-12T19:53:12.791094Z",
     "iopub.status.idle": "2026-02-12T19:53:12.801310Z",
     "shell.execute_reply": "2026-02-12T19:53:12.800795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         data1     data2\n",
      "key1                    \n",
      "a     1.076427 -0.282492\n",
      "b    -0.178197 -0.147071\n",
      "              data1     data2\n",
      "key1 key2                    \n",
      "a    one   1.177846 -0.691905\n",
      "     two   0.873589  0.536336\n",
      "b    one   0.009144 -0.914691\n",
      "     two  -0.365539  0.620548\n",
      "          mean       std  count\n",
      "key1                           \n",
      "a     1.076427  0.557175      3\n",
      "b    -0.178197  0.264941      2\n",
      "         data1     data2\n",
      "key1                    \n",
      "a     3.229281 -0.282492\n",
      "b    -0.356395 -0.147071\n",
      "Group: a, Shape: (3, 4)\n",
      "Group: b, Shape: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "# df.groupby('col')        — group rows by column values\n",
    "# .agg(func)               — apply aggregation function\n",
    "# .agg(['mean', 'sum'])    — multiple aggregations\n",
    "# .agg({'col1': 'sum', 'col2': 'mean'}) — per-column aggregation\n",
    "# .transform(func)         — apply func, return same-shape result\n",
    "# .filter(func)            — filter groups based on condition\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a'],\n",
    "                   'key2': ['one', 'two', 'one', 'two', 'one'],\n",
    "                   'data1': np.random.randn(5),\n",
    "                   'data2': np.random.randn(5)})\n",
    "\n",
    "# Group by key1, compute mean\n",
    "print(df.groupby('key1').mean(numeric_only=True))\n",
    "\n",
    "# Group by multiple keys\n",
    "print(df.groupby(['key1', 'key2']).mean(numeric_only=True))\n",
    "\n",
    "# Multiple aggregations\n",
    "print(df.groupby('key1')['data1'].agg(['mean', 'std', 'count']))\n",
    "\n",
    "# Per-column aggregation\n",
    "print(df.groupby('key1').agg({'data1': 'sum', 'data2': 'mean'}))\n",
    "\n",
    "# Iterate over groups\n",
    "for name, group in df.groupby('key1'):\n",
    "    print(f'Group: {name}, Shape: {group.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** GroupBy = split-apply-combine pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy: Transform & Filter (Slide 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T19:53:12.802693Z",
     "iopub.status.busy": "2026-02-12T19:53:12.802570Z",
     "iopub.status.idle": "2026-02-12T19:53:12.813191Z",
     "shell.execute_reply": "2026-02-12T19:53:12.812695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value  normalized\n",
      "0   a      1   -0.707107\n",
      "1   a      2    0.707107\n",
      "2   b      3   -0.707107\n",
      "3   b      4    0.707107\n",
      "4   c      5   -0.707107\n",
      "5   c    100    0.707107\n",
      "  key  value  normalized\n",
      "2   b      3   -0.707107\n",
      "3   b      4    0.707107\n",
      "4   c      5   -0.707107\n",
      "5   c    100    0.707107\n",
      "       value  normalized\n",
      "key                     \n",
      "a   1      2    0.707107\n",
      "b   3      4    0.707107\n",
      "c   5    100    0.707107\n"
     ]
    }
   ],
   "source": [
    "# .transform(func) — apply func to each group, broadcast back to original shape\n",
    "# .filter(func)    — keep/discard entire groups based on a condition\n",
    "# .apply(func)     — flexible: apply any function to each group\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'key': ['a', 'a', 'b', 'b', 'c', 'c'],\n",
    "                   'value': [1, 2, 3, 4, 5, 100]})\n",
    "\n",
    "# Transform: normalize within each group (z-score)\n",
    "df['normalized'] = df.groupby('key')['value'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "print(df)\n",
    "\n",
    "# Filter: keep only groups with mean > 3\n",
    "print(df.groupby('key').filter(lambda x: x['value'].mean() > 3))\n",
    "\n",
    "# Apply: custom function per group\n",
    "def top_n(group, n=1):\n",
    "    return group.nlargest(n, 'value')\n",
    "\n",
    "print(df.groupby('key').apply(top_n))\n",
    "\n",
    "# Fill NaN with group mean\n",
    "df2 = pd.DataFrame({'key': ['a', 'a', 'b', 'b'],\n",
    "                    'val': [1, np.nan, np.nan, 4]})\n",
    "df2['val'] = df2.groupby('key')['val'].transform(\n",
    "    lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** transform keeps original shape — great for normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Quick Reference (Slide 91)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Combining Data:</strong></p>\n",
    "<table>\n",
    "<tr><th>Tool</th><th>When to Use</th></tr>\n",
    "<tr><td><code>pd.merge()</code></td><td>Join on matching column values (SQL-style)</td></tr>\n",
    "<tr><td><code>.join()</code></td><td>Join on index (shorthand for merge)</td></tr>\n",
    "<tr><td><code>pd.concat()</code></td><td>Stack DataFrames vertically or horizontally</td></tr>\n",
    "<tr><td><code>.combine_first()</code></td><td>Patch NaN holes from another source</td></tr>\n",
    "</table>\n",
    "<p><strong>Reshaping Data:</strong></p>\n",
    "<table>\n",
    "<tr><th>Tool</th><th>Direction</th></tr>\n",
    "<tr><td><code>.pivot()</code> / <code>.pivot_table()</code></td><td>Long → Wide</td></tr>\n",
    "<tr><td><code>pd.melt()</code></td><td>Wide → Long</td></tr>\n",
    "<tr><td><code>.stack()</code></td><td>Columns → Rows</td></tr>\n",
    "<tr><td><code>.unstack()</code></td><td>Rows → Columns</td></tr>\n",
    "<tr><td><code>pd.crosstab()</code></td><td>Frequency tables</td></tr>\n",
    "</table>\n",
    "<p><strong>GroupBy Pattern:</strong> <code>split → apply → combine</code></p>\n",
    "<ul>\n",
    "<li><code>.agg()</code> — reduce each group to one row</li>\n",
    "<li><code>.transform()</code> — return same-sized result</li>\n",
    "<li><code>.filter()</code> — keep/discard entire groups</li>\n",
    "<li><code>.apply()</code> — anything goes</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** merge = SQL JOIN, concat = SQL UNION, pivot = Excel PivotTable\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
